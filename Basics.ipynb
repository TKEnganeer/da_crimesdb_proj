{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Crime Reports db\n",
    "\n",
    "In this project I built a simple database from from scratch using a dataset from a Boston crime report csv file with the Postgres database engine to perform basic SQL queries. I also created the appropriate datatypes for storing the data and the priviledges for the users (data analysts and data scientists). The advantages of using Postgres as opposed to another database engine such as SQLite is it's flexibility and scalability when it comes to multiple usership. \n",
    "\n",
    "I will create 2 user groups:\n",
    "- readonly: Users in this group can only read the data typically data analysts \n",
    "- readwrite: Users in this group have permission to read and change the data.  \n",
    "\n",
    "## Creating the Database through Python \n",
    "\n",
    "I created a database named crime_db and a schema named crimes for storing the tables of the crime data.\n",
    "\n",
    "As I am yet to make the crime_db I will start by connecting to an existing database called dq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(dbname=\"dq\", user=\"dq\")\n",
    "conn.autocommit = True                           # Autocommit = True is required for creating databases \n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE DATABASE crime_db;\")       \n",
    "conn.autocommit = False # didn't have to change this but I did as good practice  \n",
    "conn.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connected to the crime database\n",
    "conn = psycopg2.connect(dbname=\"crime_db\", user=\"dq\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE SCHEMA crimes;\") \n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Data \n",
    " \n",
    "To understand how to store my data I need to have a point of reference so I can easily remember the type of information that is in the csv file. Therefore, I have written some code below to show the structure of the boston.csv crime data and the amount of unique values that are held under each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['incident_number', 'offense_code', 'description', 'date', 'day_of_the_week', 'lat', 'long']\n",
      "['1', '619', 'LARCENY ALL OTHERS', '2018-09-02', 'Sunday', '42.35779134', '-71.13937053']\n"
     ]
    }
   ],
   "source": [
    "# Column headers and 1 row of data\n",
    "import csv \n",
    "with open('boston.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    col_headers = next(reader)\n",
    "    first_row = next(reader) \n",
    "print(col_headers)\n",
    "print(first_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incident_number\t298329\n",
      "offense_code\t219\n",
      "description\t239\n",
      "date\t1177\n",
      "day_of_the_week\t7\n",
      "lat\t18177\n",
      "long\t18177\n"
     ]
    }
   ],
   "source": [
    "# Uniqiue values in each column \n",
    "def get_col_value_set(csv_filename, col_index):\n",
    "    import csv\n",
    "    values = set()\n",
    "    with open('boston.csv','r') as f:\n",
    "        next(f)\n",
    "        reader =csv.reader(f)\n",
    "        for row in reader:\n",
    "            values.add(row[col_index])\n",
    "    return values \n",
    "\n",
    "for i in range (len(col_headers)):\n",
    "    values = get_col_value_set('boston.csv', i)\n",
    "    print(col_headers[i], len(values), sep='\\t')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the Maximum Length of the Description Column\n",
    "\n",
    "In order to create the appropriate datatypes I need to know specific information from the data in the columns. If I know the maximum length of phrase in the description column I can store it as fixed character length datatype saving memory overall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum length of any value in the description column is 58 characters long.\n"
     ]
    }
   ],
   "source": [
    "# longest value in 'description' column\n",
    "crime_descriptions = get_col_value_set('boston.csv', 2)\n",
    "max_len = 0\n",
    "for desc in crime_descriptions:\n",
    "    max_len = max(max_len, len(desc))\n",
    "\n",
    "print('The maximum length of any value in the description column is', max_len,'characters long.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['incident_number', 'offense_code', 'description', 'date', 'day_of_the_week', 'lat', 'long']\n",
      "['1', '619', 'LARCENY ALL OTHERS', '2018-09-02', 'Sunday', '42.35779134', '-71.13937053']\n",
      "['2', '1402', 'VANDALISM', '2018-08-21', 'Tuesday', '42.30682138', '-71.06030035']\n",
      "['3', '3410', 'TOWED MOTOR VEHICLE', '2018-09-03', 'Monday', '42.34658879', '-71.07242943']\n",
      "['4', '3114', 'INVESTIGATE PROPERTY', '2018-09-03', 'Monday', '42.33418175', '-71.07866441']\n",
      "['5', '3114', 'INVESTIGATE PROPERTY', '2018-09-03', 'Monday', '42.27536542', '-71.09036101']\n",
      "['6', '3820', 'M/V ACCIDENT INVOLVING PEDESTRIAN - INJURY', '2018-09-03', 'Monday', '42.29019621', '-71.07159012']\n",
      "['7', '724', 'AUTO THEFT', '2018-09-03', 'Monday', '42.30607218', '-71.0827326']\n",
      "['8', '3301', 'VERBAL DISPUTE', '2018-09-03', 'Monday', '42.32701648', '-71.10555088']\n",
      "['9', '301', 'ROBBERY - STREET', '2018-09-03', 'Monday', '42.33152148', '-71.07085307']\n"
     ]
    }
   ],
   "source": [
    "# print(col_headers)\n",
    "import csv \n",
    "with open('boston.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i in range(10):\n",
    "        print(next(reader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Datatype Choices \n",
    "\n",
    "I chose to store 'incident number' as an integer since the numbers look like they are increasing by 1 in each row, there are also around 300k unique values so saving it as a integer will remain within the range. 'Offence code' can be saved as a smallint since the codes seem to range from 3 to 4 digits long. 'description' will be varchar(70) as I know that there is no value in that column which has more than 58 characters. 'date' will be date and 'day_of_the_week' enum as they can only be the 7 days of the week. The 'lat' and 'long' columns will be stored as a decimal where I will set the precision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enum for 7 days of the week \n",
    "cur.execute(\"\"\"\n",
    "    CREATE TYPE dotw AS ENUM (\n",
    "    'Monday', 'Tuesday', 'Wednesday', 'Thursday', \n",
    "    'Friday', 'Saturday', 'Sunday');\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE crimes.boston_crimes(\n",
    "        incident_number INTEGER PRIMARY KEY,\n",
    "        offense_code smallint,\n",
    "        description varchar(70), \n",
    "        date date,\n",
    "        day_of_the_week dotw,\n",
    "        lat DECIMAL(8,6), \n",
    "        long DECIMAL(9,6)\n",
    "        );\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298329\n"
     ]
    }
   ],
   "source": [
    "# check to see in data has been correctly loaded \n",
    "with open(\"boston.csv\") as f:\n",
    "    cur.copy_expert(\"COPY crimes.boston_crimes FROM STDIN WITH CSV HEADER;\", f)\n",
    "cur.execute(\"SELECT * FROM crimes.boston_crimes\")\n",
    "\n",
    "print(len(cur.fetchall()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Privileges for Groups and Users\n",
    "\n",
    "To ensure that the users will not inherit any unautherised priveleges on the schema I started by revoking all the privileges from the public group on the public schema.\n",
    "\n",
    "I also revoked all privileges in the newly created schema. By doing this it makes it easier so I do not need to revoke the privileges when I create users and groups in the future to prevent any privileges from being granted by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"REVOKE ALL ON SCHEMA public FROM public\")\n",
    "cur.execute(\"REVOKE ALL ON DATABASE crime_db FROM public\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the read-only and read-write Groups \n",
    "\n",
    "As the readonly and read-write groups are not users they don't need login privileges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"CREATE GROUP readonly NOLOGIN;\")\n",
    "cur.execute(\"CREATE GROUP readwrite NOLOGIN;\")\n",
    "cur.execute(\"GRANT CONNECT ON DATABASE crime_db TO readonly;\")\n",
    "cur.execute(\"GRANT CONNECT ON DATABASE crime_db TO readwrite;\")\n",
    "cur.execute(\"GRANT USAGE ON SCHEMA crimes TO readonly;\")\n",
    "cur.execute(\"GRANT USAGE ON SCHEMA crimes TO readwrite;\")\n",
    "\n",
    "# assigning privileges to groups\n",
    "\n",
    "cur.execute(\"GRANT SELECT ON ALL TABLES IN SCHEMA crimes TO readonly;\")\n",
    "cur.execute(\"GRANT SELECT, INSERT, DELETE, UPDATE ON ALL TABLES IN SCHEMA crimes TO readwrite;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Created and Assigned Users - data analyst and data scientist to groups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"CREATE USER data_analyst WITH PASSWORD 'secret1';\")\n",
    "cur.execute(\"GRANT readonly TO data_analyst;\")\n",
    "cur.execute(\"CREATE USER data_scientist WITH PASSWORD 'secret2';\")\n",
    "cur.execute(\"GRANT readwrite TO data_scientist;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Database setup\n",
    "\n",
    "I tested the database setup using SQL queries on the pg_roles table and information_schema.table_privileges.\n",
    "\n",
    "For the information_schema.table_privileges I checked the privileges compared to the the SQL queries. \n",
    "\n",
    "For the pg_roles table I checked the database related privileges.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('readonly', 'SELECT')\n",
      "('readwrite', 'INSERT')\n",
      "('readwrite', 'SELECT')\n",
      "('readwrite', 'UPDATE')\n",
      "('readwrite', 'DELETE')\n"
     ]
    }
   ],
   "source": [
    "# Check that the privileges have been assigned correctly\n",
    "cur.execute(\"\"\"SELECT grantee, privilege_type\n",
    "    FROM information_schema.table_privileges\n",
    "    WHERE grantee IN ('readonly','readwrite');\"\"\")\n",
    "privileges = cur.fetchall()\n",
    "for row in privileges:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dq', True, True, True)\n",
      "('readonly', False, True, False)\n",
      "('readwrite', False, True, False)\n",
      "('data_analyst', False, True, False)\n",
      "('data_scientist', False, True, False)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspecting the privileges related to each group and user \n",
    "cur.execute(\"\"\"\n",
    "    SELECT rolname, rolsuper, rolinherit, rolcreatedb FROM pg_roles\n",
    "    WHERE rolname IN ('dq','readonly','readwrite', 'data_analyst', 'data_scientist');\n",
    "    \"\"\")\n",
    "\n",
    "for user in cur:\n",
    "    print(user)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I wanted to see how the other users and groups compared to the super user 'dq'.\n",
    "\n",
    "## Conclusion \n",
    "\n",
    "This project is just a small demonstration of how I can create a database from scratch using any csv file by connecting to the Postgres engine as a server. I installed the PostgreSQL database system and the psycopg2 Python library on my laptop to run it locally on a remote server. This can of course be scaled up when it comes to a multiple user systems. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
